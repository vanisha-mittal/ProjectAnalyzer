{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec85f1ad-bd1d-4f2b-8bc8-e39028c67ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (1.7.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (5.1.1)\n",
      "Requirement already satisfied: torch in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shree\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn sentence-transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44ddc37-c6de-4652-9b1c-d93971b22699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Folder system ready (data/, models/, outputs/)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Create main folders for organization\n",
    "base_folder = os.getcwd()\n",
    "folders = ['data', 'models', 'outputs']\n",
    "for f in folders:\n",
    "    os.makedirs(os.path.join(base_folder, f), exist_ok=True)\n",
    "\n",
    "print(\"âœ… Folder system ready (data/, models/, outputs/)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222c49e1-008a-4715-acaa-7263a62b522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "Shape: (200, 5)\n",
      "âœ… Dataset loaded successfully!\n",
      "Shape: (200, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Category</th>\n",
       "      <th>Difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the difference between compilation and...</td>\n",
       "      <td>Compilation translates source code into machin...</td>\n",
       "      <td>General Programming</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Explain the concept of polymorphism.</td>\n",
       "      <td>Polymorphism allows objects of different class...</td>\n",
       "      <td>General Programming</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Define encapsulation and give an example.</td>\n",
       "      <td>Encapsulation bundles data and methods in a cl...</td>\n",
       "      <td>General Programming</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is an abstract class, and how is it diffe...</td>\n",
       "      <td>An abstract class can't be instantiated and ca...</td>\n",
       "      <td>General Programming</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Describe the principles of Object-Oriented Pro...</td>\n",
       "      <td>OOP principles include encapsulation, inherita...</td>\n",
       "      <td>General Programming</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question Number                                           Question  \\\n",
       "0                1  What is the difference between compilation and...   \n",
       "1                2               Explain the concept of polymorphism.   \n",
       "2                3          Define encapsulation and give an example.   \n",
       "3                4  What is an abstract class, and how is it diffe...   \n",
       "4                5  Describe the principles of Object-Oriented Pro...   \n",
       "\n",
       "                                              Answer             Category  \\\n",
       "0  Compilation translates source code into machin...  General Programming   \n",
       "1  Polymorphism allows objects of different class...  General Programming   \n",
       "2  Encapsulation bundles data and methods in a cl...  General Programming   \n",
       "3  An abstract class can't be instantiated and ca...  General Programming   \n",
       "4  OOP principles include encapsulation, inherita...  General Programming   \n",
       "\n",
       "  Difficulty  \n",
       "0     Medium  \n",
       "1     Medium  \n",
       "2       Hard  \n",
       "3     Medium  \n",
       "4     Medium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder = os.path.join(base_folder, 'data')\n",
    "csv_path = os.path.join(data_folder, 'Software Questions.csv')\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Dataset not found at {csv_path}. Please place your CSV file inside the 'data' folder.\"\n",
    "    )\n",
    "\n",
    "# Try with 'utf-8', fall back to 'latin1' if decoding fails\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c866fb9-8463-418d-aad7-32013d9f8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data cleaned successfully!\n",
      "Total questions after cleaning: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "required_columns = ['Question', 'Category']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"âŒ Missing required column: '{col}' in dataset\")\n",
    "\n",
    "df.dropna(subset=['Question', 'Category'], inplace=True)\n",
    "df['Question'] = df['Question'].astype(str).str.strip()\n",
    "df['Category'] = df['Category'].astype(str).str.strip().str.lower()\n",
    "\n",
    "print(\"âœ… Data cleaned successfully!\")\n",
    "print(f\"Total questions after cleaning: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63fe0b61-a996-4dc0-97ae-0e32f806045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“š Unique Categories:\n",
      "['algorithms', 'artificial intelligence', 'back-end', 'data engineering', 'data structures', 'database and sql', 'database systems', 'devops', 'distributed systems', 'front-end', 'full-stack', 'general program', 'general programming', 'languages and frameworks', 'low-level systems', 'machine learning', 'networking', 'security', 'software testing', 'system design', 'version control', 'web development']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "print(\"\\nðŸ“š Unique Categories:\")\n",
    "print(list(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1d0927-7d6f-42be-8cc7-887943aaa338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered dataset now has 20 valid categories after removing rare ones.\n",
      "âœ… Data split into 158 training and 40 testing samples.\n"
     ]
    }
   ],
   "source": [
    "# âœ‚ï¸ Train-Test Split\n",
    "# Remove categories with only 1 sample (cannot stratify)\n",
    "category_counts = df['category_encoded'].value_counts()\n",
    "df = df[df['category_encoded'].isin(category_counts[category_counts > 1].index)]\n",
    "\n",
    "print(f\"âœ… Filtered dataset now has {df['category_encoded'].nunique()} valid categories after removing rare ones.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Question'].tolist(),\n",
    "    df['category_encoded'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['category_encoded']\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data split into {len(X_train)} training and {len(X_test)} testing samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8789c566-484a-4595-b9ab-901cc34fde7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading Sentence Transformer model... (may take a few seconds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e99f43cdd4c338f14ca6923ead733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shree\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4401a8ae1204d8b8731d575a814240e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ffd1412b84ba99a774b35c597f439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bea041c881456fa6a5ab99f441beed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07a660e4712486ba436b1640faefb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca100008641c44ef81593a00efc278d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff6c7ea2ad640eaacc22f9bf861ea8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37dc907f5834f0aa3f3bc34c819973e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade63a6b329b445bb221acae54641987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eede68351e42279610c48b475dee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdd89ec5017452b84442cc8d9b33573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”„ Loading Sentence Transformer model... (may take a few seconds)\")\n",
    "model_embed = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"âœ… Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cef54264-03ac-4152-bd2b-82209e226f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding training and test questions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204da5045a8349d49d6db8332355f708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e851aed0d243ed8ac02fbbd6910206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings generated for training and test data!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncoding training and test questions...\")\n",
    "X_train_emb = model_embed.encode(X_train, convert_to_numpy=True, batch_size=32, show_progress_bar=True)\n",
    "X_test_emb = model_embed.encode(X_test, convert_to_numpy=True, batch_size=32, show_progress_bar=True)\n",
    "print(\"âœ… Embeddings generated for training and test data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c524ee73-3920-4193-950e-d78892f61b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classifier trained successfully!\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_emb, y_train)\n",
    "print(\"âœ… Classifier trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87dd731e-558d-4816-9780-05d7b0a2c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "              algorithms       1.00      0.50      0.67         2\n",
      "                back-end       0.67      0.67      0.67         3\n",
      "         data structures       0.00      0.00      0.00         2\n",
      "        database and sql       0.00      0.00      0.00         2\n",
      "        database systems       0.00      0.00      0.00         1\n",
      "                  devops       0.38      0.75      0.50         4\n",
      "     distributed systems       0.00      0.00      0.00         1\n",
      "               front-end       0.43      1.00      0.60         3\n",
      "              full-stack       0.00      0.00      0.00         2\n",
      "     general programming       0.00      0.00      0.00         2\n",
      "languages and frameworks       0.00      0.00      0.00         2\n",
      "        machine learning       0.00      0.00      0.00         1\n",
      "              networking       0.00      0.00      0.00         1\n",
      "                security       1.00      0.67      0.80         3\n",
      "        software testing       1.00      1.00      1.00         2\n",
      "           system design       0.36      1.00      0.53         5\n",
      "         version control       1.00      1.00      1.00         2\n",
      "         web development       0.00      0.00      0.00         2\n",
      "\n",
      "                accuracy                           0.50        40\n",
      "               macro avg       0.32      0.37      0.32        40\n",
      "            weighted avg       0.39      0.50      0.40        40\n",
      "\n",
      "âœ… Accuracy: 50.0 %\n",
      "âœ… Accuracy: 50.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shree\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shree\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_emb)\n",
    "print(\"\\nðŸ“ˆ Classification Report:\")\n",
    "present_labels = np.unique(y_test)\n",
    "present_target_names = label_encoder.inverse_transform(present_labels)\n",
    "print(classification_report(y_test, y_pred, labels=present_labels, target_names=present_target_names))\n",
    "print(\"âœ… Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n",
    "\n",
    "print(\"âœ… Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0ab89f-a23f-4732-84b9-2cf51b954dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building embeddings for all questions (this may take a while)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1730a128b0584912b5dc840f89b9ce53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding index ready!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” Build Question Retrieval System\n",
    "print(\"Building embeddings for all questions (this may take a while)...\")\n",
    "all_q_embeddings = model_embed.encode(df['Question'].tolist(), convert_to_numpy=True, batch_size=32, show_progress_bar=True)\n",
    "print(\"âœ… Embedding index ready!\")\n",
    "\n",
    "def get_questions_for_stack(stack_name, top_k=5):\n",
    "    stack_name = stack_name.lower().strip()\n",
    "    query_emb = model_embed.encode([f\"Interview questions about {stack_name}\"], convert_to_numpy=True)\n",
    "    cosine_scores = util.cos_sim(query_emb, all_q_embeddings)[0].cpu().numpy()\n",
    "    top_indices = cosine_scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "    print(f\"\\nðŸ’¡ Top {top_k} questions related to '{stack_name}':\\n\")\n",
    "    for idx in top_indices:\n",
    "        q = df.iloc[idx]['Question']\n",
    "        cat = df.iloc[idx]['Category']\n",
    "        diff = df.iloc[idx]['Difficulty'] if 'difficulty' in df.columns else 'N/A'\n",
    "        print(f\"[{cat} | {diff}] {q}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46af0cb4-a532-433b-87fb-ac784903f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¡ Top 5 questions related to 'react':\n",
      "\n",
      "[front-end | N/A] Can you explain the concept of 'state' in React?\n",
      "\n",
      "[front-end | N/A] Can you explain the concept of 'state' in React?\n",
      "\n",
      "[front-end | N/A] Explain the use of hooks in React.\n",
      "\n",
      "[front-end | N/A] Explain the use of hooks in React.\n",
      "\n",
      "[languages and frameworks | N/A] Discuss the role of a package manager like npm or pip.\n",
      "\n",
      "\n",
      "ðŸ’¡ Top 5 questions related to 'python':\n",
      "\n",
      "[languages and frameworks | N/A] What are the differences between Python 2 and Python 3?\n",
      "\n",
      "[languages and frameworks | N/A] Discuss the role of a package manager like npm or pip.\n",
      "\n",
      "[machine learning | N/A] Implement a natural language processing algorithm to understand and answer user queries.\n",
      "\n",
      "[software testing | N/A] Describe the differences between manual and automated testing.\n",
      "\n",
      "[low-level systems | N/A] Build a compiler for a new programming language.\n",
      "\n",
      "\n",
      "ðŸ’¡ Top 5 questions related to 'machine learning':\n",
      "\n",
      "[machine learning | N/A] Develop a machine learning model to predict stock prices.\n",
      "\n",
      "[machine learning | N/A] Implement a natural language processing algorithm to understand and answer user queries.\n",
      "\n",
      "[machine learning | N/A] Develop a deep learning model to analyze and interpret medical images.\n",
      "\n",
      "[machine learning | N/A] Develop a machine learning algorithm to detect fake news on social media.\n",
      "\n",
      "[full-stack | N/A] Describe the process of memoization in programming.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_questions_for_stack('react')\n",
    "get_questions_for_stack('python')\n",
    "get_questions_for_stack('machine learning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38438804-5e43-4fa9-b225-3a0757ae7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§© Predicted Tech Stack: front-end\n"
     ]
    }
   ],
   "source": [
    "def predict_category(new_question):\n",
    "    new_emb = model_embed.encode([new_question], convert_to_numpy=True)\n",
    "    pred = clf.predict(new_emb)\n",
    "    category = label_encoder.inverse_transform(pred)[0]\n",
    "    print(f\"\\nðŸ§© Predicted Tech Stack: {category}\")\n",
    "\n",
    "predict_category(\"Explain the difference between state and props in React.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a863c-7028-4fae-a242-79d84368c2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
