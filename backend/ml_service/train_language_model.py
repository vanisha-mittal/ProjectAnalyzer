import os, json, joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

def load_codesearchnet(data_dir, langs=None, max_per_lang=5000):
    if langs is None:
        langs = ['python','java','javascript']
    texts, labels = [], []
    for lang in langs:
        path = os.path.join(data_dir, lang, f"{lang}.train.jsonl")
        if not os.path.exists(path):
            print(f"[!] Missing: {path}, skipping")
            continue
        with open(path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= max_per_lang:
                    break
                try:
                    obj = json.loads(line)
                    code = obj.get('code','').strip()
                    if not code:
                        continue
                    texts.append(code)
                    labels.append(lang.capitalize())
                except Exception:
                    continue
    return texts, labels

def train_language_model():
    data_dir = os.path.join('datasets','codesearchnet')
    texts, labels = load_codesearchnet(data_dir, max_per_lang=2000)
    print(f"Loaded {len(texts)} samples for language training")

    if len(texts) < 2:
        print("Not enough data to train.")
        return

    le = LabelEncoder()
    y = le.fit_transform(labels)

    vectorizer = TfidfVectorizer(max_features=20000, token_pattern=r'\w+', lowercase=False)
    X = vectorizer.fit_transform(texts)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y if len(set(y))>1 else None, random_state=42)

    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    print(classification_report(y_test, y_pred, target_names=le.classes_))

    os.makedirs('models', exist_ok=True)
    joblib.dump(clf, os.path.join('models','lang_detector_csnet.pkl'))
    joblib.dump(vectorizer, os.path.join('models','vectorizers_lang_vectorizer.pkl'))
    joblib.dump(le, os.path.join('models','lang_label_encoder.pkl'))
    print('âœ… Saved language model and vectorizer to models/')

if __name__ == '__main__':
    train_language_model()
